################################################################################
# DO NOT USE THIS DOCKERFILE!
# This is write for CUDA 12.x, which PyTorch is still far from compatible with.
################################################################################
# Dockerfile that builds 'yanwk/sd-webui-base:torch-xformers'.
# A environment for compiling latest PyTorch2 & xFormers.
################################################################################

FROM yanwk/sd-webui-base:magma AS stage-1

WORKDIR /root

RUN set -eu \
    && mkdir -p /root/wheels \
    && source /opt/intel/oneapi/setvars.sh intel64 mod ilp64

# Prepare to compile PyTorch
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install wheel setuptools numpy \
    && pip install -r https://raw.githubusercontent.com/pytorch/pytorch/master/requirements.txt

RUN git clone --depth=1 --no-tags --recurse-submodules --shallow-submodules \
        https://github.com/pytorch/pytorch.git

# # fix for fbgemm
# RUN --mount=type=cache,target=/var/cache/zypp \
#     zypper --gpg-auto-import-keys \
#         install -y --no-recommends --auto-agree-with-licenses \
#         openblas-common-devel libopenblas_pthreads-devel openblas_pthreads-devel-static \
#     && cd /root/pytorch/third_party/fbgemm \
#     && git checkout main && git pull \
#     && git submodule sync && git submodule update --init --recursive \
#     && sed -i 's/-Werror//' CMakeLists.txt \
#     && rm -rf build && cmake -B build -D FBGEMM_BUILD_BENCHMARKS=off -G Ninja \
#     && cd build && ninja && ninja install 

# Compile PyTorch
RUN --mount=type=cache,target=/root/.cache/pip \
    --mount=type=cache,target=/root/pytorch/build \
    --mount=type=cache,target=/root/pytorch/dist  \
    cd /root/pytorch \
    && python setup.py bdist_wheel -d /root/wheels


# Compile xformers
# Reduce build-targets to save time on compiling!
# https://github.com/facebookresearch/xformers/blob/main/README.md#install-troubleshooting
# https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -r https://raw.githubusercontent.com/facebookresearch/xformers/main/requirements.txt

RUN cd /root \
    && git clone --depth=1 --recurse-submodules --shallow-submodules \
        https://github.com/facebookresearch/xformers.git 

ENV TORCH_CUDA_ARCH_LIST="6.1+PTX;7.5;8.0;8.6;8.9"

RUN --mount=type=cache,target=/root/.cache/pip \
    --mount=type=cache,target=/root/xformers/build \
    --mount=type=cache,target=/root/xformers/dist \
    cd /root/xformers \
    && python setup.py bdist_wheel -d /root/wheels


# Save the result
FROM alpine:latest AS stage-final

COPY --from=stage-1 /root/wheels /wheels
