# Nightly Build 

*link:README.zh.adoc[>> 中文文档 <<]*

* Ready for DreamBooth Extension. Deps are almost latest.
** If you start from blank, you don't need any extra step, the script download everything for you.
** If you use WebUI'e extension page to install, it will install its specified version of deps.
** You could use `git clone` to download extensions, avoiding WebUI's auto `pip install`.

* Using PyTorch official nightly build, currently (2023/4/5) PyTorch 2.1 - CUDA 11.8 - CPython 3.10
* Compile-install xFormers from https://github.com/facebookresearch/xformers[GitHub].
** Compiler gen-code (for saving build time): `6.1+PTX;7.5;8.0;8.6;8.9`.
** Reference: https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/
** Try build your own link:Dockerfile-bulky[bulky] version of image to match your exactly GPUs.

## Usage

.A. Using `docker run` 
[source,sh]
----
mkdir -p storage

docker run -it \
  --name sd-webui-nightly \
  --gpus all \
  -p 7860:7860 \
  -v "$(pwd)"/storage:/home/runner \
  --env CLI_ARGS="--xformers --medvram --allow-code --api --enable-insecure-extension-access" \
  yanwk/sd-webui-base:nightly

# Update image
docker rm sd-webui-nightly
docker pull yanwk/sd-webui-base:nightly
# Then re-run 'docker run' above again
----

.B. Using `docker compose`
[source,sh]
----
git clone https://github.com/YanWenKun/sd-webui-docker-base.git

cd sd-webui-docker-base

docker compose -f nightly/docker-compose.yml up --detach

# Update image
git pull
docker compose -f nightly/docker-compose.yml pull
docker compose -f nightly/docker-compose.yml up --detach --remove-orphans
docker image prune
----

Once the app is loaded, visit http://localhost:7860/

Other usage refer to *link:../README.adoc[README]* .


## Benchmark

A simple benchmark:

----
GPU: Titan Xp (12G VRAM, Pascal, sm_61) 
python: 3.10.10

No CLI_ARGS:

torch: 1.13.1+cu117
xformers: N/A
run1    console time: 06:00    web page time: 5m 56.36s
run2    console time: 06:00    web page time: 6m 0.69s

CLI_ARGS: --xformers --medvram

torch: 1.13.1+cu117
xformers: 0.0.16
run1    console time: 03:11    web page time: 3m 7.06s
run2    console time: 03:07    web page time: 3m 7.47s

torch: 1.13.1+cu117
xformers: 0.0.17.dev473
run1    console time: 03:16    web page time: 3m 9.60s
run2    console time: 03:07    web page time: 3m 7.06s

torch: 2.1.0.dev20230313+cu118
xformers: 0.0.17+b6be33a.d20230314
run1    console time: 03:14    web page time: 3m 8.73s
run2    console time: 03:09    web page time: 3m 9.56s
run3    console time: 03:10    web page time: 3m 10.52s
----

It's safe to say that the stable version of PyTorch & xFormers is performing good enough.
Unless you have GPU-specific issue to deal with, it's not necessary to use nightly version for performance purpose.


## CUDA 12.x

(2023/3/13) I tried building PyTorch with CUDA 12.1, the errors flooded me. There's not much I can do. It's better to wait for other people at this moment.
